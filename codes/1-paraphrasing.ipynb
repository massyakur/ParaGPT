{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO71BmuWVWTbilsd9SKeqtZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"5vIg4u1urAlQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"M6Z8EXwQgXCW"},"outputs":[],"source":["# import the dataset from gsheets\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","import gspread\n","from google.auth import default\n","creds, _ = default()\n","\n","gc = gspread.authorize(creds)\n","\n","worksheet = gc.open('dataset').sheet1"]},{"cell_type":"code","source":["# get_all_values gives a list of rows.\n","rows = worksheet.get_all_values()\n","# print(rows)\n","\n","import pandas as pd\n","df = pd.DataFrame.from_records(rows)\n","\n","# creating columns name\n","df.columns = df.iloc[0]\n","df = df.iloc[1:]"],"metadata":{"id":"9Y50y7VRk47J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ChatGPT"],"metadata":{"id":"kO6o20ur7nks"}},{"cell_type":"markdown","source":["Paraphrase using https://chat.openai.com/chat website"],"metadata":{"id":"xeJH9XAM7s9d"}},{"cell_type":"markdown","source":["# GPT-3"],"metadata":{"id":"Ncm2MgOMg4Hl"}},{"cell_type":"code","source":["!pip install openai"],"metadata":{"id":"eTJP8onHhbXL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import openai\n","import time\n","\n","openai.organization = \"\"\n","openai.api_key = \"\"\n","\n","for i, reference in df[\"reference\"].items():\n","  if df.loc[i, \"gpt3\"] != '':\n","    continue\n","  else:\n","    try:\n","      response = openai.Completion.create(\n","          engine=\"text-davinci-003\", \n","          prompt=f\"paraphrase:{reference}\",\n","          # prompt=f\"Act as AI sentence paraphraser and just paraphrase:{reference}\",\n","          max_tokens=512\n","          )\n","      df.loc[i, \"gpt3\"] = response[\"choices\"][0][\"text\"].replace(\"\\n\", \"\")\n","      time.sleep(1)\n","    except:\n","      print(f'{i} - Error')\n","      time.sleep(5)\n","      continue\n","  # if i == 10000:\n","  #   break"],"metadata":{"id":"GY8jsbU9hdkQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# update the gsheets\n","cell_list = worksheet.range(\"D2:D10002\")\n","\n","for i, val in enumerate(df[\"gpt3\"]):\n","  # if cell_list[i].value != '':\n","  #   continue\n","  # if val == '':\n","  #   print(i)\n","  #   break\n","  cell_list[i].value = val\n","  # print(i)\n","\n","worksheet.update_cells(cell_list)"],"metadata":{"id":"hwMs1gBCp_8k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# T5"],"metadata":{"id":"uXwK6B_cg4wm"}},{"cell_type":"code","source":["# !pip install git+https://github.com/PrithivirajDamodaran/Parrot.git\n","!pip install git+https://github.com/massyakur/Parrot_Paraphraser"],"metadata":{"id":"BX3nj-ToqsQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import libraries\n","from parrot import Parrot\n","import torch\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"F8gJ-TXMqv6q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for reproducibility\n","def random_state(seed):\n","  torch.manual_seed(seed)\n","  if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","random_state(1234)"],"metadata":{"id":"DlwR4_jyrSoU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# init the fine-tuned model (make sure you init ONLY once if you integrate this to your code)\n","parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\") # , use_gpu=False)"],"metadata":{"id":"Il2ylJLErXLm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# stop_n = 10000\n","\n","for i, reference in df[\"reference\"].iteritems():\n","  if df.loc[i, \"t5_0\"] != '':\n","    continue\n","  else:\n","    try:\n","      responses = parrot.augment(input_phrase=reference, \n","                                use_gpu=True,\n","                                do_diverse=False,\n","                                diversity_ranker=\"levenshtein\",\n","                                adequacy_threshold = 0.5,\n","                                fluency_threshold = 0.5\n","                                )\n","      for j, response in enumerate(responses):\n","        column_name = f\"t5_{j}\"\n","        df.loc[i, column_name] = response[0]\n","        # print(f\"{i}-{column_name} = {response[0]}\")\n","        if j == 2:\n","          break\n","    except:\n","      print(f\"{i} - No paraphrases returned\")\n","  # if i == stop_n:\n","  #   break"],"metadata":{"id":"HB9cIfQfsQWj"},"execution_count":null,"outputs":[]}]}